{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33305a6b-bdde-4b0e-856a-547fd6778656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/18 05:33:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CorruptRecord</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0xffff73248f40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CorruptRecord\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.cores.max\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60637b1-faf6-488e-9b2f-ac9635f8b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "# id,name,age,salary,address,nominee\n",
    "employee_schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "    StructField('salary', IntegerType(), True),\n",
    "    StructField('address', StringType(), True),\n",
    "    StructField('nominee', StringType(), True),\n",
    "    StructField('_bad_record', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d52c39-81e5-4d5e-9cd6-25522ec1ea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+---------+--------+--------------------------------------------+\n",
      "|id |name    |age|salary|address  |nominee |_bad_record                                 |\n",
      "+---+--------+---+------+---------+--------+--------------------------------------------+\n",
      "|1  |Manish  |26 |75000 |bihar    |nominee1|NULL                                        |\n",
      "|2  |Nikita  |23 |100000|up       |nominee2|NULL                                        |\n",
      "|3  |Pritam  |22 |150000|Bangalore|India   |3,Pritam,22,150000,Bangalore,India,nominee3 |\n",
      "|4  |Prantosh|17 |200000|Kolakata |India   |4,Prantosh,17,200000,Kolakata,India,nominee4|\n",
      "|5  |Vikash  |31 |300000|NULL     |nominee5|NULL                                        |\n",
      "+---+--------+---+------+---------+--------+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df = spark.read.format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('inferschemaa', 'false')\\\n",
    "            .schema(employee_schema)\\\n",
    "            .option('mode', 'PERMISSIVE')\\\n",
    "            .option('columnNameOfCorruptRecord', '_bad_record')\\\n",
    "            .load('/opt/spark-data/input/employee_data.csv')\n",
    "\n",
    "employee_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d947be76-fd55-4b12-874f-9a7bbfe1c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of storing bad records in a file\n",
    "\n",
    "employee_schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "    StructField('salary', IntegerType(), True),\n",
    "    StructField('address', StringType(), True),\n",
    "    StructField('nominee', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f440fb5-6da3-4b41-95b2-ceafa2dc20fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+---------+--------+\n",
      "|id |name    |age|salary|address  |nominee |\n",
      "+---+--------+---+------+---------+--------+\n",
      "|1  |Manish  |26 |75000 |bihar    |nominee1|\n",
      "|2  |Nikita  |23 |100000|up       |nominee2|\n",
      "|3  |Pritam  |22 |150000|Bangalore|India   |\n",
      "|4  |Prantosh|17 |200000|Kolakata |India   |\n",
      "|5  |Vikash  |31 |300000|NULL     |nominee5|\n",
      "+---+--------+---+------+---------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "employee_df = spark.read.format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('inferschemaa', 'false')\\\n",
    "            .schema(employee_schema)\\\n",
    "            # .option('mode', 'PERMISSIVE')\\ Not Allowed with badRecordsPath --- atleast in databricks\n",
    "            .option('badRecordsPath', '/opt/spark-data/output/')\\\n",
    "            .load('/opt/spark-data/input/employee_data.csv')\n",
    "\n",
    "employee_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b849886f-ddd8-4bc3-9d92-610fb439ab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Did not work for me since `badRecordsPath` not available for vanilla spark, present in databricks \n",
    "## Solution for me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5b3246-e574-4157-8e27-f940a161f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_schema = StructType([\n",
    "    StructField('id', IntegerType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "    StructField('salary', IntegerType(), True),\n",
    "    StructField('address', StringType(), True),\n",
    "    StructField('nominee', StringType(), True),\n",
    "    StructField('_bad_record', StringType(), True)\n",
    "])\n",
    "\n",
    "employee_df = spark.read.format('csv')\\\n",
    "            .option('header', 'true')\\\n",
    "            .option('inferschemaa', 'false')\\\n",
    "            .schema(employee_schema)\\\n",
    "            .option('mode', 'PERMISSIVE')\\\n",
    "            .option('columnNameOfCorruptRecord', '_bad_record')\\\n",
    "            .load('/opt/spark-data/input/employee_data.csv')\n",
    "\n",
    "employee_df_good = employee_df.filter('_bad_record IS NULL')\n",
    "employee_df_bad = employee_df.filter('_bad_record IS NOT NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415f98f6-a94c-40c1-bdce-d9d62cd4ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+------+-------+--------+-----------+\n",
      "|id |name  |age|salary|address|nominee |_bad_record|\n",
      "+---+------+---+------+-------+--------+-----------+\n",
      "|1  |Manish|26 |75000 |bihar  |nominee1|NULL       |\n",
      "|2  |Nikita|23 |100000|up     |nominee2|NULL       |\n",
      "|5  |Vikash|31 |300000|NULL   |nominee5|NULL       |\n",
      "+---+------+---+------+-------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df_good.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c5a6de9-2163-4bb7-9efe-64a524c2ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+---------+-------+--------------------------------------------+\n",
      "|id |name    |age|salary|address  |nominee|_bad_record                                 |\n",
      "+---+--------+---+------+---------+-------+--------------------------------------------+\n",
      "|3  |Pritam  |22 |150000|Bangalore|India  |3,Pritam,22,150000,Bangalore,India,nominee3 |\n",
      "|4  |Prantosh|17 |200000|Kolakata |India  |4,Prantosh,17,200000,Kolakata,India,nominee4|\n",
      "+---+--------+---+------+---------+-------+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df_bad.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53204ead-36c9-407e-822d-13d4b727b7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
